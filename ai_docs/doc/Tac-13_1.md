# Agentic Horizon — Lesson (Transcript Excerpt)

> **Note:** Texto convertido a Markdown, preservando el contenido original.

---

This will likely be the most controversial lesson of Agentic Horizon.

There will be three buckets of engineers that watch this lesson:

- Those who dismiss this idea  
- Those who give it a shot  
- Those who say, *"This is what I've been looking for."*

Agents of today have many problems. Most of them can be solved with great context engineering and great agentic prompt engineering.

But there is one massive problem that persists no matter how great your context engineering or agentic prompt engineering becomes:

## The massive problem: agents forget

Traditional software improves as it's used—storing user analytics, usage data, and patterns that create algorithms. Agents of today don't.

The massive problem with agents is this:

- Your agents forget.  
- And that means your agents don't learn.

There are a few solutions, but each has their own problems:

- **Memory files** are global forced context that always loads.
  - Expertise requires breaking rules when the time is right.
  - Memory files must be manually updated, consuming your time (or your team's time).
- Then we have **prime prompts**, **sub agents**, and **skills**:
  - Powerful agentic tools.
  - But they still require manual updates when you want to add new information or steer your agents.

So, what if you could take the best tool for the job of engineering agents to the next level:

- Teaching your agents to **act, learn, and reuse** its expertise **at runtime**
- Creating **agent experts**

## Agent experts

The difference between a generic agent and an agent expert is simple:

- One executes and forgets.  
- The other executes and learns.

In this lesson, I'll execute and you'll learn to build agents that turn actions into expertise:

- Automatically storing the right information
- Reusing it with **no human in the loop**

This is key. This is what makes an expert an expert:

- You don't need to tell an expert to learn—it’s in their DNA.
- Real experts don’t relearn their craft every time they have a new task.
- True experts are always learning: updating their mental model.

This mental model is, simply put:

- A **data structure** that evolves over time.

With each useful action, experts accumulate:

- Information
- Examples
- Ultimately: expertise around a specific topic

This is key:

- You're not trying to solve every problem.
- You're trying to solve the one that matters the most to you, your business, and your customers.

If this sounds familiar, it should:

- You—and everyone you admire—has a strong mental model around a specific domain down to individual problems.

That mental model is a data structure that helps you solve problems better and faster as you:

- Act
- Learn
- Reuse expertise

So, in the world of agent coding, prompt engineering, and context engineering:

## What is an agent expert?

The agent expert is a concrete form of a:

- **Self-improving template metaprompt**

That’s a mouthful. Let’s break it down:

### Metaprompts
Metaprompts are prompts that build other prompts.

### Template metaprompts
Template metaprompts are prompts that build other prompts with a specific purpose and structure.

This is a key leverage point of agent coding discussed in lesson three of tactical agent coding:

- This is how you teach your agents to operate and build as you do.

### Self-improving prompts
A self-improving prompt updates itself, related prompts, or an isolated file with new information that will be used during your agent’s next execution.

When we put it all together:

- Self-improving + template + metaprompt  
= **Self-improving template metaprompt**

If that doesn’t make sense, don’t worry—we’ll walk through it step by step.

There are people who are proficient.
There are engineers who are great.

But experts are in their own class above the rest because they never stop learning.

Experts grow.  
They update their knowledge about their domain.

The expert understands the game never ends except for one condition:

- The moment they stop learning.

I certainly want experts operating my codebase and products—not generic agents that forget and that you have to boot up over and over and manage memory files manually.

That’s the focus of this lesson:

- **Agent experts**

---

## Meta-agentics (building blocks)

In this lesson, we’ll walk through meta agentics—or put plainly:

- Meta prompts
- Meta sub agents
- Meta skills

We’ll do this to showcase the atoms that make up the agent expert.

We’ll use our orchestrator agent from lesson 4 to showcase agent experts that operate specific areas of your small to large codebase extraordinarily well.

We’ll then take a look at a product-focused agent expert that lets you build adaptive user experiences:

- A whole new untapped type of UI/UX waiting to be unlocked by engineers willing to push the boundaries of agents.

Let’s start with meta agentics:

- The building blocks for not just your agent expert, but your entire agentic layer.

At their core, meta agentics help you build elements of:

- The system that builds the system.

These include:

- Meta prompts
- Meta agents
- Meta skills

They greatly increase your output as an agentic engineer—with or without agent experts.

Let’s run through each to showcase their value proposition.

In this agent experts codebase (loot box below):

1. **Meta prompt**: create a new version of a question prompt called **question with mermaid diagrams**
2. **Meta agent**: create a new planner agent that reads and executes the plan prompt (scale planning in parallel)
3. **Meta skill**: create a start orchestrator skill that kicks off the front end and back end of our multi-agent orchestration app (lesson 4)

Meta agentics are critical because they let you build more of your agentic layer faster:

- Prompts writing prompts
- Agents building agents
- Skills building skills

There is no codebase I create that does not have meta agentics.

Every codebase must have meta agentics.

Let this be your reminder to keep a stack of these ready to go—foundation for quickly spinning up new agentic layers.

---

## Demonstration outputs

We have our **question with mermaid diagrams** built out.

In classic agentic prompt format:

- Great structure
- Variables take user question
- Mermaid diagrams enhance understanding

We then had our **meta agent** build out a new planner agent:

- It reads an existing prompt
- Fires it as a sub agent
- Reuses and scales existing prompts into their own agents

Lastly, **meta skill** turned an existing “start orchestrator” process into a concrete skill.

If we open up the start orchestrator skill:

- Exact purpose
- Flags
- Where to go and how to start them
- Opens Chrome when finished

All built thanks to meta agentics:

- Meta prompts
- Meta agents
- Meta skills

---

## Are meta-agentics agent experts?

Important question:

Are these meta agentics agent experts?

They’re acting, but they’re missing a key piece:

- They’re not learning at all.

Nothing inside the metaprompt, meta agent, or meta skill updated automatically.

Therefore:

- These are **not** agent experts.

A key factor of an agent expert:

- They must learn on their own.

Agent experts must learn on their own.

You teach them to learn by templating your engineering, but after that:

- They must accumulate and manage their own expertise.

---

## Expertise files as mental models (database example)

Concrete example: prompts that start to look more like an expert operating your codebase.

Inside the commands directory where prompts are stored:

- An `experts/` directory
- A **database expert**

Two key prompts:

- A question prompt
- A self-improve prompt

Before deep dive, execute a question to the database agent:

- `/quest database question`
- “How does information flow between our database tables? Write your report in this temp file.”

Critical behavior:

1. The agent first reads the **expertise file**
2. It compares its understanding against the actual code
3. It reports

### What is the expertise file?
The expertise file is:

- The **mental model** of the problem space for your agent expert

Differentiator:

- It contains a working mental model—like you or your team would.

This is not a source of truth.

It’s like your own mental model:

- Not the code
- Not comments
- Not PRDs
- A working memory structure you update

The true source of truth is always:

- The code

But auxiliary memory and mental models are still ultra valuable.

---

## Workflow: validate mental model → report

Question prompt workflow:

1. Read expertise file (static reference)
2. Validate assumptions against codebase
3. Report

The expertise is a high-level map of what the agent has built up:

- Database module
- Connection pool
- Query patterns
- Data models
- Migration patterns
- Sync/distribution utilities

This is a mental model—not a duplicate source of truth.

---

## Self-improve prompt (learning step)

We built it with a **self-improve** prompt.

Purpose:

- Compare expertise file against the codebase
- Detect missing/outdated info
- Update expertise
- Keep it accurate as a memory reference for future tasks

The self-improve prompt:

- Validates
- Updates
- Runs closed-loop checks
- Enforces constraints (e.g., max lines, valid YAML)

You can use any data structure:

- YAML, TOML, JSON, CSV, etc.

Key idea:

- The agent maintains its own mental model, synced with ground truth.

---

## The 3-step agent expert loop

Agent experts have three concrete steps:

1. **Act** (take a useful action)
2. **Learn** (store new info)
3. **Reuse** (use it next execution)

In the database example:

- We have **Reuse** (question prompt reads expertise)
- We have **Learn** (self-improve updates expertise)
- We are missing **Act** (no code modifications yet)

So it’s a partial expert.

Next example:

- A websocket expert will include action.

---

## Websocket expert: action + plan/build/improve

We use the 3-step workflow:

- **SLP: plan → build → improve**

Example task:

- Add a session-based counter to the app navbar displaying total websocket events.

Key properties:

- No searching needed
- The expert already knows where things are via its mental model

We also scale confidence:

- Create 3 agents
- Run the same question prompt in parallel
- Collocate on correctness

The websocket expert prompt:

- Composes multiple prompts
- Uses sub agents
- Has a self-improve step to update expertise

The self-improve structure mirrors:

- Get diff
- Read current expertise
- Validate against code
- Identify discrepancies
- Update expertise
- Validation checks (max lines, valid YAML)

---

## Why this matters

Without agent expertise:

- You have to track changes manually
- Rebuild understanding each time
- Lose speed and trust at scale

With agent experts:

- The agent keeps track of its mental model
- Updates expertise as code changes
- Reuses it automatically
- Stays focused: one agent, one prompt, one purpose

---

## Closing thought

The websocket expert:

- Performs beyond out-of-the-box agents
- Because it contains a mental model of work already completed
- It knows the websocket system better than anyone—quickly

And we can scale this:

- 3 agents
- 5 agents
- 10 agents
- Depending on importance and need for correctness

You can see non-determinism in which files each agent consumes—but expertise reduces the search burden and increases consistency.