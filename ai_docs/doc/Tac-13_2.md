# Agentic Horizon — Transcript Excerpt (Markdown)

> **Nota:** Texto convertido a Markdown y organizado con encabezados para lectura rápida. Se preserva el contenido original.

---

## Orchestrator: synthesizing results & scaling compute

Assumed. So five files there, four files here. And so we can concretely see this.

Our orchestrator can synthesize all the results. And very interesting here, let's check this out:

Right? Web stalker 3 didn't complete the task.

And so this is another key value proposition to scale up your compute:

- Sometimes if you throw five agents at the problem, only one makes it.
- One finds something the other didn't.
- The other finds some things the others didn't.
- Then you compose that together and you get a better result.

Okay, so this is correct.

My mental model can validate this:

- We in fact do have 21 types across... I don't know if there are seven categories, but there are some 20 websocket events.
- Agent life cycle, agent communication, orchestrator, chat, system, blah blah blah.

Okay, we had our agent experts build this out, validate this work, and you can see the UI flickering here because our build websocket agent is updating the store and soon it's going to update the actual front end based on the plan.

We've talked about this in previous agenda horizon lessons, but we are reducing and delegating our context.

- The plan step here took **80K tokens**.
- Our top level agent here has its context completely protected.
- All it did was pass the return plan into the builder.
- And once the builder finishes it's going to pass the get diff.

So just the work being done:

- Right now we can run `gs`.
- We can see all the changes that's happened.
- And this work is going to be passed right into our self-improve.

And we're actually going to run:

- `self-improve` with `true`

So we are indeed going to look at `get diff`.

This is that first parameter here, right?

- Argument hint check: `get diff`

And this is what guides our agent to update the changes that have been made.

So this is going to be really cool to see this end to end.

But you can see here:

- Three agent experts completed the work.

And if we want to, we could have even scaled this up further:

> Create three more experts using the opus model and have them same prompt to ultra validate.

Okay, so we can do all types of things once we get these powerful orchestration systems and powerful expert systems up and running.

---

## Build output → get diff → self-improve loop

All right, so we're still building, but you can see here:

- We have that brand new websocket events coming in.
- This is getting live updated.

Frankly, the live update could have been the reason that expert 3 failed. Who knows? Don't care.

But here we go:

- We can see that diff.

So this is part of that last step of our builder:

- It's summarizing the work done by looking at `get diff`.

And then it's going to pass its work:

- Our top level agent is going to pass off this work right into step three:
  - The **self-improve prompt**.

You can see it's written out exactly as is:

- There is zero confusion in this agentic prompt.
- We're going to **plan**, we're going to **build**, and then we're going to **improve**.
- And we're delegating to sub agents.

Ultra ultra powerful stuff here.

Websocket build done:

- **61k tokens**
- **41 tool uses**

And we should be able to see this here.

Refresh.

There we go:

- Websocket event one.
- There's another one coming in there.

And so you can see here:

- Our opus orchestrator agents are fired off here.
- And in our last step: our self-improve websocket expert is kicking off.
- It is making updates.

Things have changed in the system, and so this is going to be reflected:

- Brand new lines that have not been committed.
- We have `on message received`.
- We have our websocket counter event.
- This is brand new.
- The total lines have increased.

I don't know how important lines are here. I guess it helps the agent search through total line numbers and maybe run some gotos faster, but this is maybe something that could be played with.

We can see if we really want this.

But then we have something really cool here:

- Session state is keeping track of the state counter for all websocket messages.

In the UI:

- Total **167 websocket events**.

So, that change was oneshotted.

And you can bet that the guarantee of that performance was increased by having an agent expert that knows that code better than anyone or anything.

---

## Abstractions don’t matter — core four does

We're entering this really weird phase where you can truly create high performance agents and all you need is:

- The right information
- The right prompts
- And then you can compose them into whatever you want to

Many engineers might be thinking:

> Just build a skill.

That can be a skill.  
That could be an agent.  
That could be a sub agent.  
Whatever.

It doesn't matter.

Build whatever abstraction you want:

- Build your own MCP servers
- Build your own skills
- Do whatever you want

I always focus on the foundational units:

- **Context**
- **Model**
- **Prompt**
- **Tools**

The core four.

Everything is that—just with some fancy tooling, a little bit of code structure.

Build a skill if you want.  
Build a custom agent if you want.  
Overwrite the system prompt if you want.

There it is:

- Our agent has finished.
- 20 tool uses.
- Almost 60k tokens.

You have to protect your context windows here and build focus agents that do one thing.

Total of 15 minutes or something.

And we have a great workflow summary:

- Built into the report format
- Summarizing each step

Looks great:

- Exact precise changes made.

Many engineers get super hyped when an agent changes a million things.

I get super hyped when agents change just the right things.

Surgical changes:

- Five lines
- 17 lines
- Nine lines
- Four lines

And then we have our discrepancies change.

We can always prove it with Git.

Here’s our expertise file GDF.

What changed?

- You can see the exact updates your agent made to its expertise, to its mental model.

Something really interesting:

- Their mental model becomes yours.

---

## Where agent experts shine

More and more I come into these expertise files.

Favorite use cases:

- Billing systems (saved me money)
- Systems that require security
- Complex niche systems
- Large codebases with many interconnected systems spread far apart

Your average agent wouldn’t know to connect the dots like that.

Even the best agents and best models:

- It would take quite a bit of time to search through everything and draw all the connections.

That’s why agent expertise and mental models are so powerful.

We have:

- **650 lines** of a map — a wrapper around websocket capability between backend and frontend of the multi-agent orchestration system.

This scales very very well.

We can see the get diff, we can see everything updated.

And if there’s something we don’t like, something wrong or off:

- We’re not going to update the expertise file directly.

This emphasizes:

- Build the system that builds the system.

You want to update:

- The agentics that are operating your code
- The self-improve step that operates your expertise

These are the same thing.

Key message of tactical agent coding and agent horizon:

- Build the system that builds the system.
- Do not work on the application layer.
- You’re wasting your time.

We’re building the agentic layer:

- The ring around your codebase that can operate it for you, with you, and without you.

So:

- Don’t directly update the expertise file.
- Teach your agents how to update it so they can maintain it.

---

## Locking in the agent expert workflow: Act, Learn, Reuse

We have the three steps:

- **Act**
- **Learn**
- **Reuse**

Planning is where we are concretely reusing this information.

Also, we’re reusing in our question prompt.

Where are we acting?

- In the **build** step.

After the plan is generated using the expertise and validated against raw source of truth:

- We build against that plan.

That build prompt is the act step:

- Useful action taken against the codebase.

Expertise must be updated and synced:

- Self-improve is our learn step.
- Agents learn and update its mental model around websockets.

If this has clicked for you, you might already be thinking of agent experts to deploy.

If you stop right now:

- You should have tons of valuable things to build in your agentic layer with agent experts.

---

## Favorite agent expert examples

Top one (literally saved me money):

- **Billing agent expert**
  - Webhooks responding to billing events
  - Backend + frontend
  - Build an expert here — don’t miss anything
  - Higher risk → higher intensity → experts shine

More examples:

- **Database experts**
- **DevOps agent experts**
- **Integration agent experts** (tricky in-house + third-party, multi-way)
- **ML / data science agent experts**
- **API agent experts** (keep frontend/backend synced)
- **Data types / data models expert**
  - Keep types in sync across monorepo + microservices
  - Great first expert: small set of files, easy to reference & maintain

Note:

- These are relatively simple examples so far:
  - No custom tools
  - No specialized system prompt
  - This is just the beginning

---

## Product agent experts: adaptive UI/UX (shopping example)

Let’s step outside codebase experts and look at product agent experts.

We’ll look at a seed of an idea:

- Using agent experts to enhance user experiences.

Example:

- Nile shopping application (rough mock)
- Agents are not ready to be shopping recommendation engines yet (too slow)
- But the key ideas are here: agent experts inside UIs

In the demo UI:

- Act, learn, reuse panel is visible.

Per-user mental model:

- When deployed at scale, we have a data structure per user.
- Personalization to the max.
- Especially when combined with generative UI.

Example flow:

- New user → no expertise yet
- User views “Nvidia DGX Spark” (mock product)
  - That is an action the agent can learn
- User adds to cart
  - Another learn opportunity
- Page regenerates
  - Reuse step shapes UI

The expertise file per user includes structured data:

- Viewed products
- Added to cart
- Checked out

We can add recency weighting and priorities.

Key:

- X means Y (user action implies preference signals)
- In real engines you’d use the full user graph, categories, price ranges, etc.
- This is the seed of the big idea

The system prompt embeds dynamic variables:

- Viewed products
- Added to cart
- Checked out products
- Available categories

And uses static variables for things like:

- Products per section
- Section ranges

So:

- Agent expertise applied per user
- Prompt guides individual user experience by generating components on the fly

As usage grows:

- Expertise file gets overloaded
- Now we hit challenges and tradeoffs

---

## Challenges & tradeoffs

### 1) Seeding
Seeding is the first version of the expertise.

Like joining a new job:

- Rough rundown of codebase, tools, processes
- Review process, branches, docs

You seed this info for your experts.

Approach:

- Stay hands-off unless you know the desired shape.
- Not too verbose.
- Not too high level.
- Define this in the self-improve prompt.

Start simple.

Run self-improve from blank:

- It creates the expertise
- Then you tweak self-improve and rerun
- Repeat until agent stops finding new things

### 2) “Another source of truth?”
No:

- Not source of truth
- A mental model
- Self-improve keeps it updated for you

This is the trend:

- Teach agents how to do things.

Gap between engineers:

- Who taught their agents how to run things vs who didn’t
- Who keeps prompting the same loop by hand months later

### 3) Finite context
You do not want infinite growth.

Constraints:

- Keep under a limit (example: max lines)
- Enforce via prompt + validation
- Choose compressed representations (YAML, JSON, etc.)

### 4) False expertise
Agents can update something wrong.

This error rate will go down, but won’t go to zero:

- Humans also have false expertise
- Expect it

### 5) Too granular expertise
Prompt engineering issue:

- Need to specify how detailed vs vague it should be
- Prioritize actionable high-value expertise over verbose documentation

Also:

- Let agents decide what’s important when possible.
- It’s their mental model, not yours.

### 6) Too many experts
Eventually you’ll need processes:

- When to use an expert vs generic agent
- Fresh looks matter sometimes

Later patterns:

- Routers
- Reminders
- Auto-pick experts by reference points in descriptions

For now:

- If you’re building many experts, that’s good.
- Make it a team habit: check experts file before starting.

---

## When to use agent experts

Agent experts are great for:

- User-specific use cases (future products will be agent-driven)
- Codebase areas that are high risk and high complexity:
  - Billing
  - Security
  - Complex, niche systems
  - Large systems with deep interconnections

They can catch:

- Revenue-changing details
- Security-specific details

As your product grows:

- Complexity increases
- Specialization increases
- Experts become more valuable

Also use experts when:

- High error rates in an area (generic agents keep getting it wrong)
- You can tune self-improve to force attention to critical constraints

---

## When not to use agent experts

Avoid if:

- The problem doesn’t evolve over time
- You don’t need a maintained mental model
- You’re in a brand-new, generic codebase with little unique value yet

Also avoid when:

- You yourself don’t have a mental model yet
- If you don’t understand the problem, you can’t judge expert performance
- You’ll build an expert that makes things worse

Memory files note:

- You can auto-update them, but they’re global/always-loaded
- Better: dedicated isolated expertise file + explicitly invoke the expert

Abstractions note:

- Skills, sub agents, agents — any is fine
- Everything boils down to core four:
  - Context, model, prompt, tools

---

## Closing perspective

Experts are true value generators:

- Expertise drives innovation and change

In your codebases:

- For niche information or specialized operators, consider an agent expert.

In products:

- Experiment with product-focused agent experts for adaptive UI/UX.

Final question:

Do you want:

- A generalist that forgets every time, or
- An expert that remembers and learns so next time it starts with a powerful working understanding?

In the final lesson of Agentic Horizon:

- Codebase architecture for an agent-first world
- Optimal shapes to scale agentic layer performance
- Tie back to the big idea:

**Build the system that builds the system.**  
**Prioritize agentics.**