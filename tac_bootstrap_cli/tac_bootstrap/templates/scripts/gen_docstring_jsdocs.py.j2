#!/usr/bin/env python3
# /// script
# dependencies = ["python-dotenv"]
# ///
"""
gen_docstring_jsdocs.py

Adds IDK-format docstrings/JSDoc to Python and TypeScript/JavaScript files using LLM.
Generated for project: {{ config.project.name }}

Providers:
- claude: Uses Claude Code CLI (no API key needed, recommended)
- api: Uses OpenAI-compatible API (requires OPENAI_API_KEY or OLLAMA)

Modes:
- add: add docs only if missing (default, safest)
- overwrite: replace docs entirely (dangerous - commit first!)
- complement: append missing sections without deleting anything

IDK concept:
- IDK line must be 5–12 domain keywords (kebab-case), NO sentences, NO verbs.

Usage:
  # Using Claude Code CLI (recommended - no API key needed)
  python gen_docstring_jsdocs.py --repo {{ config.paths.app_root | default("src") }} --provider claude --dry-run

  # Using OpenAI API
  python gen_docstring_jsdocs.py --repo {{ config.paths.app_root | default("src") }} --provider api --dry-run
"""

from __future__ import annotations

import argparse
import ast
import json
import os
import re
import shutil
import subprocess
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple, Union
import tempfile
import urllib.request
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

TAG_TAXONOMY = [
    "expert:backend", "expert:frontend", "expert:data", "expert:infra", "expert:observability",
    "level:L1", "level:L2", "level:L3", "level:L4", "level:L5",
    "topic:auth", "topic:routing", "topic:logging", "topic:db", "topic:caching",
    "topic:queue", "topic:api", "topic:performance",
]

IDK_PREFIX = "IDK:"
DEFAULT_IDK_RULES = (
    "IDK rules:\n"
    "- Provide 5–12 INFORMATION DENSE KEYWORDS\n"
    "- NO sentences, NO verbs, NO filler words\n"
    "- Use canonical technical nouns; kebab-case\n"
    "- Prefer terms from the provided canonical/global IDK list when relevant\n"
    "- If uncertain, choose broader canonical terms\n"
)

IGNORE_DIRS = {
    ".git", "node_modules", ".venv", "venv", "__pycache__", "dist", "build",
    ".next", ".turbo", ".cache", "target", "vendor", ".idea", ".vscode"
}

# Project-specific configuration from template
# Default app root: {{ config.paths.app_root | default("src") }}
# Default language: {{ config.project.language }}
# Project name: {{ config.project.name }}


# ---------------------------
# OpenAI-compatible client
# ---------------------------
class OpenAICompatClient:
    def __init__(
        self,
        base_url: str,
        api_key: str,
        model: str,
        timeout_s: int = 120,
        temperature: float = 0.2,
        max_tokens: int = 520,
        extra_headers_json: Optional[str] = None,
        extra_body_json: Optional[str] = None,
        endpoint: str = "chat/completions",
    ):
        self.base_url = base_url.rstrip("/")
        self.api_key = api_key
        self.model = model
        self.timeout_s = timeout_s
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.endpoint = endpoint.lstrip("/")
        self.extra_headers = json.loads(extra_headers_json) if extra_headers_json else {}
        self.extra_body = json.loads(extra_body_json) if extra_body_json else {}

    def chat(self, messages: List[Dict[str, str]]) -> str:
        url = f"{self.base_url}/{self.endpoint}"
        body: Dict[str, Any] = {
            "model": self.model,
            "messages": messages,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
        }
        body.update(self.extra_body)

        data = json.dumps(body).encode("utf-8")
        req = urllib.request.Request(url, data=data, method="POST")
        req.add_header("Content-Type", "application/json")
        if self.api_key:
            req.add_header("Authorization", f"Bearer {self.api_key}")
        for k, v in self.extra_headers.items():
            req.add_header(str(k), str(v))

        with urllib.request.urlopen(req, timeout=self.timeout_s) as resp:
            raw = resp.read().decode("utf-8", errors="replace")
            payload = json.loads(raw)

        return payload["choices"][0]["message"]["content"]


# ---------------------------
# Claude Code CLI client
# ---------------------------
class ClaudeCodeClient:
    """Client that uses Claude Code CLI for LLM calls."""

    def __init__(
        self,
        model: str = "sonnet",
        timeout_s: int = 300,
        claude_path: Optional[str] = None,
    ):
        self.model = model
        self.timeout_s = timeout_s
        self.claude_path = claude_path or os.getenv("CLAUDE_CODE_PATH", "claude")

    def chat(self, messages: List[Dict[str, str]]) -> str:
        """Execute prompt via Claude Code CLI."""
        # Combine messages into a single prompt
        prompt_parts = []
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            if role == "system":
                prompt_parts.append(f"<system>\n{content}\n</system>\n")
            else:
                prompt_parts.append(content)

        full_prompt = "\n".join(prompt_parts)

        # Write prompt to temp file for large prompts
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write(full_prompt)
            prompt_file = f.name

        try:
            cmd = [
                self.claude_path,
                "--model", self.model,
                "--dangerously-skip-permissions",
                "--print",
                "--output-format", "text",
            ]

            # Read prompt from file
            with open(prompt_file, 'r') as f:
                prompt_content = f.read()

            result = subprocess.run(
                cmd,
                input=prompt_content,
                capture_output=True,
                text=True,
                timeout=self.timeout_s,
                cwd=os.getcwd(),
            )

            if result.returncode != 0:
                error_msg = result.stderr or "Unknown error"
                raise RuntimeError(f"Claude CLI failed: {error_msg}")

            return result.stdout.strip()

        finally:
            # Cleanup temp file
            try:
                os.unlink(prompt_file)
            except OSError:
                pass


# ---------------------------
# Helpers
# ---------------------------
def is_ignored_path(p: Path) -> bool:
    return any(part in IGNORE_DIRS for part in p.parts)

def repo_rel(repo: Path, p: Path) -> str:
    return str(p.resolve().relative_to(repo.resolve())).replace("\\", "/")

def read_text(p: Path) -> str:
    return p.read_text(encoding="utf-8", errors="replace")

def write_text(p: Path, s: str) -> None:
    p.write_text(s, encoding="utf-8")

def backup_file(p: Path) -> None:
    bak = p.with_suffix(p.suffix + ".bak")
    if not bak.exists():
        shutil.copy2(p, bak)

def normalize_llm_output(s: str) -> str:
    s = s.strip()
    s = re.sub(r"^```[a-zA-Z0-9]*\n", "", s)
    s = re.sub(r"\n```$", "", s)
    return s.strip()

def iter_code_files(
    repo: Path,
    include_glob: Optional[str] = None,
    recursive: bool = True,
    exclude_patterns: Optional[List[str]] = None,
    extensions: Optional[List[str]] = None
) -> Iterable[Path]:
    """Iterate over code files with optional filtering."""
    if extensions is None:
        extensions = [".py", ".ts", ".tsx", ".js", ".jsx"]

    exclude_patterns = exclude_patterns or []

    def should_exclude(p: Path) -> bool:
        rel_path = str(p.relative_to(repo))
        return any(re.search(pattern, rel_path) for pattern in exclude_patterns)

    if include_glob:
        for p in repo.glob(include_glob):
            if p.is_file() and not is_ignored_path(p) and not should_exclude(p):
                yield p
        return

    glob_pattern = "**/*" if recursive else "*"
    for p in repo.glob(glob_pattern):
        if not p.is_file() or is_ignored_path(p):
            continue
        if p.suffix in extensions and not p.name.endswith(".d.ts"):
            if not should_exclude(p):
                yield p

def extract_window(text: str, start_line: int, max_lines: int) -> str:
    lines = text.splitlines()
    start = max(0, start_line - 1)
    end = min(len(lines), start + max_lines)
    return "\n".join(lines[start:end])

def get_changed_files(repo: Path) -> List[Path]:
    """Get list of changed files from git (unstaged + staged)."""
    changed = []
    try:
        # Get unstaged changes
        result = subprocess.run(
            ["git", "diff", "--name-only", "HEAD"],
            cwd=repo,
            capture_output=True,
            text=True,
            check=True
        )
        changed.extend(result.stdout.strip().split("\n") if result.stdout.strip() else [])

        # Get staged changes
        result = subprocess.run(
            ["git", "diff", "--cached", "--name-only"],
            cwd=repo,
            capture_output=True,
            text=True,
            check=True
        )
        changed.extend(result.stdout.strip().split("\n") if result.stdout.strip() else [])

        # Deduplicate and convert to Path objects
        unique_files = list(set(changed))
        return [repo / f for f in unique_files if f]
    except subprocess.CalledProcessError as e:
        print(f"Warning: git command failed: {e}", file=sys.stderr)
        return []
    except FileNotFoundError:
        print("Warning: git not found in PATH", file=sys.stderr)
        return []


# ---------------------------
# Docs frontmatter IDK loader
# ---------------------------
FRONTMATTER_RE = re.compile(r"^---\s*$", re.M)

def parse_frontmatter(text: str) -> Optional[str]:
    """
    Return raw YAML frontmatter (string) or None.
    """
    # Find first two '---' lines
    lines = text.splitlines()
    if not lines or lines[0].strip() != "---":
        return None
    for i in range(1, min(len(lines), 200)):  # keep cheap
        if lines[i].strip() == "---":
            return "\n".join(lines[1:i])
    return None

def parse_idk_from_frontmatter_yaml(yaml_text: str) -> List[str]:
    """
    Minimal parser for:
      idk:
        - term
        - term2
    or:
      idk: [a, b]
    """
    idk: List[str] = []
    # inline list
    m = re.search(r"(?m)^\s*idk\s*:\s*\[(.*?)\]\s*$", yaml_text)
    if m:
        inside = m.group(1)
        parts = [p.strip().strip('"').strip("'") for p in inside.split(",")]
        return [p for p in parts if p]

    # block list
    lines = yaml_text.splitlines()
    in_idk = False
    base_indent = None
    for ln in lines:
        if re.match(r"^\s*idk\s*:\s*$", ln):
            in_idk = True
            base_indent = len(ln) - len(ln.lstrip())
            continue
        if in_idk:
            # end if indentation goes back or line is a new key
            indent = len(ln) - len(ln.lstrip())
            if ln.strip() and indent <= (base_indent or 0) and re.match(r"^\s*[A-Za-z0-9_]+\s*:", ln):
                break
            m2 = re.match(r"^\s*-\s*(.+?)\s*$", ln)
            if m2:
                term = m2.group(1).strip().strip('"').strip("'")
                if term:
                    idk.append(term)
    return idk

def detect_domain_from_path(relpath: str) -> str:
    """
    Heuristic:
    - docs/<domain>/... => <domain>
    - src/<domain>/...  => <domain>
    - services/<name>/... => services
    else => "unknown"
    """
    parts = relpath.split("/")
    if len(parts) >= 2 and parts[0] in {"docs", "src"}:
        return parts[1]
    if len(parts) >= 2 and parts[0] in {"services", "apps", "packages"}:
        return parts[0]
    return "unknown"

def build_docs_idk_index(repo: Path) -> Dict[str, List[str]]:
    """
    Index canonical/global IDK by "domain" based on docs/<domain>/**/*.md frontmatter.
    Returns domain -> merged unique idk terms (order preserved).
    """
    out: Dict[str, List[str]] = {}
    seen: Dict[str, set] = {}

    docs = repo / "docs"
    if not docs.exists():
        return out

    for p in docs.rglob("*.md"):
        if is_ignored_path(p):
            continue
        rel = repo_rel(repo, p)
        dom = detect_domain_from_path(rel)
        fm = parse_frontmatter(read_text(p))
        if not fm:
            continue
        terms = parse_idk_from_frontmatter_yaml(fm)
        if not terms:
            continue
        if dom not in out:
            out[dom] = []
            seen[dom] = set()
        for t in terms:
            if t not in seen[dom]:
                seen[dom].add(t)
                out[dom].append(t)
    return out


# ---------------------------
# Python symbol detection + docstring manipulation
# ---------------------------
@dataclass
class PyTarget:
    kind: str
    name: str
    lineno: int
    indent: str
    is_private: bool = False

def parse_python_targets(text: str, public_only: bool = False) -> List[PyTarget]:
    out: List[PyTarget] = []
    try:
        tree = ast.parse(text)
    except Exception:
        return out

    lines = text.splitlines()

    class V(ast.NodeVisitor):
        def __init__(self):
            self.class_stack: List[str] = []

        def _indent(self, lineno: int) -> str:
            s = lines[lineno - 1] if 1 <= lineno <= len(lines) else ""
            return s[: len(s) - len(s.lstrip(" \t"))]

        def visit_ClassDef(self, node: ast.ClassDef):
            is_private = node.name.startswith("_")
            if public_only and is_private:
                return
            name = ".".join(self.class_stack + [node.name]) if self.class_stack else node.name
            out.append(PyTarget("class", name, node.lineno, self._indent(node.lineno), is_private))
            self.class_stack.append(node.name)
            self.generic_visit(node)
            self.class_stack.pop()

        def visit_FunctionDef(self, node: ast.FunctionDef):
            is_private = node.name.startswith("_")
            if public_only and is_private:
                return
            kind = "method" if self.class_stack else "function"
            name = ".".join(self.class_stack + [node.name]) if self.class_stack else node.name
            out.append(PyTarget(kind, name, node.lineno, self._indent(node.lineno), is_private))
            self.generic_visit(node)

        def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):
            self.visit_FunctionDef(node)  # type: ignore[arg-type]

    V().visit(tree)
    return out

TRIPLE_QUOTE_RE = re.compile(r'^(\s*)([rubfRUBF]{0,2})("""|\'\'\')')

def find_python_docstring_block(text: str, def_line_no: int) -> Optional[Tuple[int, int, str, str]]:
    """
    Return (start_idx, end_idx_excl, quote, body)
    """
    lines = text.splitlines(True)
    i = def_line_no - 1
    if not (0 <= i < len(lines)):
        return None
    j = i
    while j < len(lines) and not lines[j].strip().endswith(":"):
        j += 1
    j += 1

    while j < len(lines):
        s = lines[j].strip()
        if not s or s.startswith("#"):
            j += 1
            continue
        break
    if j >= len(lines):
        return None
    m = TRIPLE_QUOTE_RE.match(lines[j])
    if not m:
        return None
    quote = m.group(3)
    start = j

    after = lines[j][m.end():]
    if quote in after:
        body = after.split(quote, 1)[0]
        return (start, start + 1, quote, body.strip("\n"))

    k = start + 1
    body_lines = [lines[start][m.end():]]
    while k < len(lines):
        if quote in lines[k]:
            before, _ = lines[k].split(quote, 1)
            body_lines.append(before)
            end = k + 1
            body = "".join(body_lines)
            return (start, end, quote, body.strip("\n"))
        body_lines.append(lines[k])
        k += 1
    return None

def replace_python_docstring_body(text: str, start: int, end: int, quote: str, new_body: str) -> str:
    lines = text.splitlines(True)
    indent_match = TRIPLE_QUOTE_RE.match(lines[start])
    indent = indent_match.group(1) if indent_match else ""
    prefix = indent_match.group(2) if indent_match else ""
    inner_indent = indent
    rebuilt = []
    rebuilt.append(f"{inner_indent}{prefix}{quote}\n")
    for ln in new_body.strip("\n").splitlines():
        rebuilt.append(f"{inner_indent}{ln.rstrip()}\n")
    rebuilt.append(f"{inner_indent}{quote}\n")
    return "".join(lines[:start] + rebuilt + lines[end:])

def insert_python_docstring(text: str, target: PyTarget, body: str) -> str:
    lines = text.splitlines(True)
    i = target.lineno - 1
    if not (0 <= i < len(lines)):
        return text
    j = i
    while j < len(lines) and not lines[j].strip().endswith(":"):
        j += 1
    j += 1
    inner_indent = target.indent + " " * 4
    body = body.strip("\n").replace('"""', r'\"\"\"')
    doc = [f'{inner_indent}"""\n']
    for ln in body.splitlines():
        doc.append(f"{inner_indent}{ln.rstrip()}\n")
    doc.append(f'{inner_indent}"""\n')
    return "".join(lines[:j] + doc + lines[j:])


# ---------------------------
# TS: JSDoc manipulation
# ---------------------------
JSDOC_START = re.compile(r"^\s*/\*\*")
JSDOC_END = re.compile(r".*\*/\s*$")

TS_SYMBOL_PATTERNS: List[Tuple[re.Pattern, str]] = [
    (re.compile(r"^\s*export\s+class\s+([A-Za-z0-9_]+)"), "class"),
    (re.compile(r"^\s*export\s+interface\s+([A-Za-z0-9_]+)"), "interface"),
    (re.compile(r"^\s*export\s+type\s+([A-Za-z0-9_]+)"), "type"),
    (re.compile(r"^\s*export\s+function\s+([A-Za-z0-9_]+)\s*\("), "function"),
    (re.compile(r"^\s*export\s+const\s+([A-Za-z0-9_]+)\s*="), "const"),
]

@dataclass
class TSTarget:
    kind: str
    name: str
    line: int
    is_private: bool = False

def find_jsdoc_block_above(lines: List[str], symbol_line_idx: int, lookback: int = 30) -> Optional[Tuple[int, int, str]]:
    start_search = max(0, symbol_line_idx - lookback)
    for i in range(symbol_line_idx - 1, start_search - 1, -1):
        if JSDOC_END.match(lines[i].rstrip("\n")):
            for j in range(i, start_search - 1, -1):
                if JSDOC_START.match(lines[j].rstrip("\n")):
                    block = "".join(lines[j:i+1])
                    return (j, i + 1, block)
    return None

def parse_ts_targets(text: str, public_only: bool = False) -> List[TSTarget]:
    out: List[TSTarget] = []
    lines = text.splitlines(True)
    for i, line in enumerate(lines):
        for pat, kind in TS_SYMBOL_PATTERNS:
            m = pat.match(line)
            if m:
                name = m.group(1)
                is_private = name.startswith("_")
                if public_only and is_private:
                    continue
                out.append(TSTarget(kind, name, i + 1, is_private))
    return out

def insert_ts_jsdoc(text: str, symbol_line: int, jsdoc_block: str) -> str:
    lines = text.splitlines(True)
    idx = symbol_line - 1
    block = jsdoc_block.strip("\n")
    if not block.startswith("/**"):
        block = "/**\n" + block + "\n*/"
    if not block.endswith("\n"):
        block += "\n"
    return "".join(lines[:idx] + [block] + lines[idx:])

def replace_ts_jsdoc(text: str, start: int, end: int, new_block: str) -> str:
    lines = text.splitlines(True)
    block = new_block.strip("\n")
    if not block.startswith("/**"):
        block = "/**\n" + block + "\n*/"
    if not block.endswith("\n"):
        block += "\n"
    return "".join(lines[:start] + [block] + lines[end:])


# ---------------------------
# Prompts with local IDK
# ---------------------------
PY_REQUIRED = ["Responsibility:", "Tags:", "Ownership:", "Invariants:", "Side effects:", "Inputs:", "Outputs:", "Failure modes:", IDK_PREFIX]
TS_REQUIRED = ["Responsibility:", "Tags:", "Ownership:", "Invariants:", "Side effects:", "Failure modes:", IDK_PREFIX]

def missing_sections(existing: str, required: List[str]) -> List[str]:
    lower = existing.lower()
    miss = [sec for sec in required if sec.lower() not in lower]
    return miss

def prompt_python_missing(existing: str, missing: List[str], file_path: str, name: str, kind: str, snippet: str, canonical_idk: List[str]) -> List[Dict[str, str]]:
    system = (
        "You generate ONLY missing sections to append to an existing Python docstring body.\n"
        "Do NOT modify existing text. Do NOT repeat existing sections.\n"
        "Return ONLY the lines to append (no triple quotes, no markdown).\n"
        + DEFAULT_IDK_RULES
    )
    user = f"""Existing docstring BODY (reference only):
---BEGIN EXISTING---
{existing.strip()}
---END EXISTING---

Missing sections to generate (ONLY these):
{chr(10).join('- ' + m for m in missing)}

Allowed tags: {", ".join(TAG_TAXONOMY)}

Canonical/global IDK terms for this domain (prefer when relevant):
{", ".join(canonical_idk) if canonical_idk else "NONE"}

Symbol: {name} ({kind})
File: {file_path}
Project: {{ config.project.name }}

Code snippet (authoritative):
{snippet}

IMPORTANT:
- For {IDK_PREFIX} output: produce 5–12 comma-separated keywords ONLY (no sentences).
Example: {IDK_PREFIX} cqrs, outbox, idempotency, transactions, correlation-id
"""
    return [{"role": "system", "content": system}, {"role": "user", "content": user}]

def prompt_python_full(file_path: str, name: str, kind: str, snippet: str, canonical_idk: List[str]) -> List[Dict[str, str]]:
    system = (
        "You generate Python docstring bodies (no triple quotes). Be accurate and conservative.\n"
        "Do NOT invent behavior not visible in the code snippet.\n"
        + DEFAULT_IDK_RULES
    )
    user = f"""Create a Python docstring BODY.

Constraints:
- Use only allowed tags: {", ".join(TAG_TAXONOMY)}
- Include {IDK_PREFIX} once (5–12 keywords, no sentences).

Canonical/global IDK terms for this domain (prefer when relevant):
{", ".join(canonical_idk) if canonical_idk else "NONE"}

Template:
Responsibility: <1 line>
Tags: <comma-separated allowed tags>
Ownership: <layer + MUST NOTs>
Invariants:
  - MUST/MUST NOT ...
Side effects:
  - ...
Inputs:
  - ...
Outputs:
  - ...
Failure modes:
  - ...
{IDK_PREFIX} <k1>, <k2>, ...

Symbol: {name} ({kind})
File: {file_path}
Project: {{ config.project.name }}

Code snippet:
{snippet}
"""
    return [{"role": "system", "content": system}, {"role": "user", "content": user}]

def prompt_ts_missing(existing_block: str, missing: List[str], file_path: str, name: str, kind: str, snippet: str, canonical_idk: List[str]) -> List[Dict[str, str]]:
    system = (
        "You generate ONLY missing lines to append INSIDE an existing JSDoc block.\n"
        "Do NOT modify existing lines. Do NOT repeat existing sections.\n"
        "Return ONLY new JSDoc lines starting with ' * '. No /** */.\n"
        + DEFAULT_IDK_RULES
    )
    user = f"""Existing JSDoc (reference only):
---BEGIN EXISTING---
{existing_block.strip()}
---END EXISTING---

Missing items to generate (ONLY these):
{chr(10).join('- ' + m for m in missing)}

Allowed tags: {", ".join(TAG_TAXONOMY)}

Canonical/global IDK terms for this domain (prefer when relevant):
{", ".join(canonical_idk) if canonical_idk else "NONE"}

Symbol: {name} ({kind})
File: {file_path}
Project: {{ config.project.name }}

Code snippet:
{snippet}

IMPORTANT:
- For {IDK_PREFIX} line: output exactly like:
 * {IDK_PREFIX} routing, api, validation, structured-logging, correlation-id
(no sentences)
"""
    return [{"role": "system", "content": system}, {"role": "user", "content": user}]

def prompt_ts_full(file_path: str, name: str, kind: str, snippet: str, canonical_idk: List[str]) -> List[Dict[str, str]]:
    system = (
        "You generate complete JSDoc blocks. Be accurate and conservative.\n"
        "Return ONLY a JSDoc block including /** */.\n"
        + DEFAULT_IDK_RULES
    )
    user = f"""Create a JSDoc block.

Constraints:
- Must include: Responsibility, Tags, Ownership, Invariants, Side effects, Failure modes, {IDK_PREFIX}
- Use only allowed tags: {", ".join(TAG_TAXONOMY)}
- {IDK_PREFIX}: 5–12 keywords, no sentences.

Canonical/global IDK terms for this domain (prefer when relevant):
{", ".join(canonical_idk) if canonical_idk else "NONE"}

Symbol: {name} ({kind})
File: {file_path}
Project: {{ config.project.name }}

Code snippet:
{snippet}
"""
    return [{"role": "system", "content": system}, {"role": "user", "content": user}]


# ---------------------------
# Processing
# ---------------------------
def process_python_file(
    client: OpenAICompatClient,
    repo: Path,
    path: Path,
    mode: str,
    dry_run: bool,
    backup: bool,
    snippet_lines: int,
    sleep_s: float,
    domain_idk: Dict[str, List[str]],
    public_only: bool = False
) -> Tuple[bool, int]:
    text = read_text(path)
    rel = repo_rel(repo, path)
    dom = detect_domain_from_path(rel)
    canonical_idk = domain_idk.get(dom, [])

    targets = parse_python_targets(text, public_only=public_only)
    if not targets:
        return False, 0
    targets.sort(key=lambda t: t.lineno, reverse=True)

    changed = False
    edits = 0

    for t in targets:
        block = find_python_docstring_block(text, t.lineno)
        has_doc = block is not None

        if mode == "add" and has_doc:
            continue

        snippet = extract_window(text, t.lineno, snippet_lines)

        if mode == "overwrite":
            msgs = prompt_python_full(rel, t.name, t.kind, snippet, canonical_idk)
            body = normalize_llm_output(client.chat(msgs))
            if IDK_PREFIX.lower() not in body.lower():
                body = body.rstrip() + f"\n{IDK_PREFIX} unknown\n"
            if has_doc:
                s, e, quote, _ = block
                new_text = replace_python_docstring_body(text, s, e, quote, body)
            else:
                new_text = insert_python_docstring(text, t, body)

        elif mode == "complement" and has_doc:
            s, e, quote, existing_body = block
            miss = missing_sections(existing_body, PY_REQUIRED)
            if not miss:
                continue
            msgs = prompt_python_missing(existing_body, miss, rel, t.name, t.kind, snippet, canonical_idk)
            addition = normalize_llm_output(client.chat(msgs))
            merged = existing_body.rstrip() + "\n\n" + addition.strip() + "\n"
            new_text = replace_python_docstring_body(text, s, e, quote, merged)

        else:
            # add missing or complement missing doc => full create
            msgs = prompt_python_full(rel, t.name, t.kind, snippet, canonical_idk)
            body = normalize_llm_output(client.chat(msgs))
            if IDK_PREFIX.lower() not in body.lower():
                body = body.rstrip() + f"\n{IDK_PREFIX} unknown\n"
            new_text = insert_python_docstring(text, t, body)

        if new_text != text:
            text = new_text
            changed = True
            edits += 1

        if sleep_s > 0:
            time.sleep(sleep_s)

    if changed and not dry_run:
        if backup:
            backup_file(path)
        write_text(path, text)

    return changed, edits


def process_ts_file(
    client: OpenAICompatClient,
    repo: Path,
    path: Path,
    mode: str,
    dry_run: bool,
    backup: bool,
    snippet_lines: int,
    sleep_s: float,
    domain_idk: Dict[str, List[str]],
    public_only: bool = False
) -> Tuple[bool, int]:
    text = read_text(path)
    rel = repo_rel(repo, path)
    dom = detect_domain_from_path(rel)
    canonical_idk = domain_idk.get(dom, [])

    lines = text.splitlines(True)
    targets = parse_ts_targets(text, public_only=public_only)
    if not targets:
        return False, 0
    targets.sort(key=lambda t: t.line, reverse=True)

    changed = False
    edits = 0

    for t in targets:
        idx = t.line - 1
        js = find_jsdoc_block_above(lines, idx)
        has_jsdoc = js is not None

        if mode == "add" and has_jsdoc:
            continue

        snippet = extract_window(text, t.line, snippet_lines)

        if mode == "overwrite":
            msgs = prompt_ts_full(rel, t.name, t.kind, snippet, canonical_idk)
            block = normalize_llm_output(client.chat(msgs))
            if IDK_PREFIX.lower() not in block.lower():
                # minimal fix
                block = block.rstrip() + f"\n * {IDK_PREFIX} unknown\n */"
            if has_jsdoc:
                s, e, _ = js
                new_text = replace_ts_jsdoc(text, s, e, block)
            else:
                new_text = insert_ts_jsdoc(text, t.line, block)

        elif mode == "complement" and has_jsdoc:
            s, e, existing_block = js
            miss = missing_sections(existing_block, TS_REQUIRED)
            if not miss:
                continue
            msgs = prompt_ts_missing(existing_block, miss, rel, t.name, t.kind, snippet, canonical_idk)
            addition = normalize_llm_output(client.chat(msgs))

            existing_lines = existing_block.splitlines(True)
            insert_at = None
            for i in range(len(existing_lines) - 1, -1, -1):
                if "*/" in existing_lines[i]:
                    insert_at = i
                    break
            if insert_at is None:
                continue

            add_lines = []
            for ln in addition.splitlines():
                ln = ln.rstrip()
                if not ln:
                    continue
                if not ln.lstrip().startswith("*"):
                    add_lines.append(f" * {ln}\n")
                else:
                    content = ln.lstrip().lstrip("*").lstrip()
                    add_lines.append(f" * {content}\n")

            merged_block = "".join(existing_lines[:insert_at] + [" *\n"] + add_lines + existing_lines[insert_at:])
            new_text = replace_ts_jsdoc(text, s, e, merged_block)

        else:
            msgs = prompt_ts_full(rel, t.name, t.kind, snippet, canonical_idk)
            block = normalize_llm_output(client.chat(msgs))
            new_text = insert_ts_jsdoc(text, t.line, block)

        if new_text != text:
            text = new_text
            lines = text.splitlines(True)
            changed = True
            edits += 1

        if sleep_s > 0:
            time.sleep(sleep_s)

    if changed and not dry_run:
        if backup:
            backup_file(path)
        write_text(path, text)

    return changed, edits


def validate_api_config(client: Union[OpenAICompatClient, ClaudeCodeClient]) -> bool:
    """Validate API configuration by making a simple test request."""
    try:
        test_msg = [{"role": "user", "content": "Say 'ok' only."}]
        client.chat(test_msg)
        return True
    except Exception as e:
        print(f"ERROR: API validation failed: {e}", file=sys.stderr)
        if hasattr(client, 'base_url'):
            print(f"Base URL: {client.base_url}", file=sys.stderr)
        print(f"Model: {client.model}", file=sys.stderr)
        return False


def main() -> int:
    # Environment variable defaults for Ollama
    default_base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434/v1/")
    default_model = os.getenv("OLLAMA_MODEL", "llama3.2")
    default_api_key = os.getenv("OPENAI_API_KEY", "ollama")

    ap = argparse.ArgumentParser(
        description="Docstring/JSDoc generator for {{ config.project.name }} using LLM providers.",
        epilog="WARNING: Always commit your code before using 'overwrite' mode!"
    )
    ap.add_argument("--repo", default="{{ config.paths.app_root | default('src') }}")
    ap.add_argument("--include-glob", default=None, help="Glob pattern for files to include")
    ap.add_argument("--exclude", action="append", help="Regex patterns to exclude files (can be used multiple times)")

    # Provider selection
    ap.add_argument("--provider", choices=["claude", "api"], default="claude",
                    help="LLM provider: 'claude' uses Claude Code CLI (no API key), 'api' uses OpenAI-compatible API")

    # Claude Code configuration
    ap.add_argument("--claude-model", default="sonnet", help="Claude model for CLI (sonnet, opus, haiku)")
    ap.add_argument("--claude-path", default=None, help="Path to claude CLI (default: from CLAUDE_CODE_PATH or 'claude')")

    # OpenAI/Ollama configuration
    ap.add_argument("--base-url", default=default_base_url, help=f"API base URL (default: {default_base_url})")
    ap.add_argument("--api-key", default=default_api_key, help="API key (default: from OPENAI_API_KEY env or 'ollama')")
    ap.add_argument("--model", default=default_model, help=f"Model name (default: {default_model})")
    ap.add_argument("--endpoint", default="chat/completions")
    ap.add_argument("--timeout-s", type=int, default=120)
    ap.add_argument("--temperature", type=float, default=0.2)
    ap.add_argument("--max-tokens", type=int, default=520)
    ap.add_argument("--extra-headers-json", default=None)
    ap.add_argument("--extra-body-json", default=None)

    ap.add_argument("--mode", choices=["add", "overwrite", "complement"], default="add",
                    help="add=only if missing (safest), complement=add missing sections, overwrite=replace all (dangerous)")
    ap.add_argument("--dry-run", action="store_true", help="Preview changes without modifying files")
    ap.add_argument("--no-backup", action="store_true", help="Skip creating .bak files")
    ap.add_argument("--snippet-lines", type=int, default=220)
    ap.add_argument("--sleep-s", type=float, default=0.0, help="Sleep seconds between API calls (for rate limiting)")
    ap.add_argument("--changed-only", action="store_true", help="Process only git-changed files")
    ap.add_argument("--no-recursive", action="store_true", help="Process only files in top-level directory")
    ap.add_argument("--public-only", action="store_true", help="Exclude private functions/methods (starting with _)")

    args = ap.parse_args()

    repo = Path(args.repo).resolve()
    if not repo.exists() or not repo.is_dir():
        print(f"ERROR: Directory not found: {repo}", file=sys.stderr)
        return 2

    # Create client based on provider
    client: Union[OpenAICompatClient, ClaudeCodeClient]
    if args.provider == "claude":
        print(f"Using Claude Code CLI (model: {args.claude_model})")
        client = ClaudeCodeClient(
            model=args.claude_model,
            timeout_s=args.timeout_s,
            claude_path=args.claude_path,
        )
    else:
        print(f"Using OpenAI-compatible API (model: {args.model})")
        client = OpenAICompatClient(
            base_url=args.base_url,
            api_key=args.api_key,
            model=args.model,
            timeout_s=args.timeout_s,
            temperature=args.temperature,
            max_tokens=args.max_tokens,
            extra_headers_json=args.extra_headers_json,
            extra_body_json=args.extra_body_json,
            endpoint=args.endpoint,
        )

        # Validate API configuration at startup (only for API provider)
        print("Validating API configuration...")
        if not validate_api_config(client):
            print("\nPlease check your API configuration and try again.", file=sys.stderr)
            return 1

    # Build canonical/global IDK index from docs frontmatter
    domain_idk = build_docs_idk_index(repo)

    # Determine file extensions based on project language
    {% if config.project.language == "python" %}
    default_extensions = [".py"]
    {% elif config.project.language == "typescript" %}
    default_extensions = [".ts", ".tsx"]
    {% elif config.project.language == "javascript" %}
    default_extensions = [".js", ".jsx"]
    {% else %}
    default_extensions = [".py", ".ts", ".tsx", ".js", ".jsx"]
    {% endif %}

    # Get files to process
    if args.changed_only:
        changed_files = get_changed_files(repo)
        # Filter for relevant extensions
        files = [f for f in changed_files if f.suffix in default_extensions and not f.name.endswith(".d.ts")]
    else:
        files = list(iter_code_files(
            repo,
            include_glob=args.include_glob,
            recursive=not args.no_recursive,
            exclude_patterns=args.exclude,
            extensions=default_extensions
        ))

    if not files:
        print("No code files found to process.")
        return 0

    backup = not args.no_backup
    total_changed = 0
    total_edits = 0
    errors = 0

    print(f"Project: {{ config.project.name }}")
    print(f"Mode: {args.mode}")
    print(f"Loaded canonical IDK from docs/ for domains: {', '.join(sorted(domain_idk.keys())) or 'none'}")
    print(f"Scanning {len(files)} file(s)...")
    if args.dry_run:
        print("DRY-RUN mode: no files will be modified\n")

    for p in files:
        try:
            if p.suffix == ".py":
                changed, edits = process_python_file(
                    client, repo, p, args.mode, args.dry_run, backup,
                    args.snippet_lines, args.sleep_s, domain_idk, args.public_only
                )
            elif p.suffix in {".ts", ".tsx", ".js", ".jsx"}:
                changed, edits = process_ts_file(
                    client, repo, p, args.mode, args.dry_run, backup,
                    args.snippet_lines, args.sleep_s, domain_idk, args.public_only
                )
            else:
                continue

            if changed:
                total_changed += 1
                total_edits += edits
                action = "DRY-RUN would change" if args.dry_run else "Changed"
                print(f"{action}: {repo_rel(repo, p)}  (+{edits} edit(s))")

        except Exception as e:
            errors += 1
            print(f"WARNING: Error processing {repo_rel(repo, p)}: {e}", file=sys.stderr)
            # Continue processing remaining files

    print("\n" + "="*60)
    print("Done.")
    print(f"Files changed: {total_changed}")
    print(f"Edits applied: {total_edits}")
    if errors > 0:
        print(f"Errors encountered: {errors}")
    if args.dry_run:
        print("Dry-run mode: no files were modified.")
    else:
        if backup:
            print("Backups: created *.bak next to modified files (first time only).")

    # Return 0 if at least some files succeeded, even if some failed
    return 0 if (total_changed > 0 or len(files) == 0 or errors < len(files)) else 1


if __name__ == "__main__":
    raise SystemExit(main())
